---
title:  "MCP 란"

categories:
  - AI
tags:
  - AI
  - MCP
  - LLM

date: 2025-06-04
thumbnail: "/assets/img/thumbnail/mcp_thumbnail.jpg"
---

MCP 란
=====

Model Context Protocol (MCP)는 LLM(대형 언어 모델)과의 상호작용을 위한 프로토콜입니다. MCP는 LLM이 특정 작업을 수행하기 위해 필요한 컨텍스트를 제공하는 데 중점을 둡니다. 이 프로토콜은 LLM이 더 나은 응답을 생성할 수 있도록 돕기 위해 설계되었습니다.

MCP는 LLM이 작업을 수행하는 데 필요한 정보를 명확하게 전달하고, LLM이 해당 정보를 기반으로 최적의 응답을 생성할 수 있도록 지원합니다. 이를 통해 LLM의 성능을 향상시키고, 사용자와의 상호작용을 보다 효율적으로 만들 수 있습니다.

LLM vs LLM Agent
=====

| **정의**	     | LLM	 | LLM Agent   |
|-------------|-----------------------------|----------------------------------------|
| **주요 역할**	  | 대형 언어 모델 (예: GPT-3, GPT-4)	 | LLM을 활용한 에이전트 (예: AutoGPT, BabyAGI)    |
| **Tool 사용**	 | 자연어 처리, 텍스트 생성 등 단일 작업 수행	  | 복잡한 태스크를 계획하고 실행하는 에이전트|
| **Memory**	 | 없음 (컨텍스트 제한) | 있음 (대화 기록, 작업 히스토리 기억 가능)   |
| **Tool 사용**	 | 	불가능 (내부 모델 능력에만 의존)| 가능 (API, 계산기, DB, 웹 브라우저 등 외부 리소스 활용)  |
| **Planner**	 | 	없음| 있음 (도구를 언제/어떻게 쓸지 판단하고 순서 계획)  |
| **실행 방식**	  |정적인 응답 → 입력 1개 → 출력 1개|  동적인 행동 → 입력 → 툴 호출 → 결과 해석 → 반복|
| **유연성**	  | 낮음 (미리 학습된 지식만 활용 가능)	      |  높음 (실시간 검색, 계산, API 활용 가능)|
| **지속적 작업**	 | 	 어려움   | 가능 (여러 단계를 거치는 장기 과제 처리) |

즉 LLM은 단순히 입력에 대한 응답을 생성하는 반면, LLM Agent는 LLM을 활용하여 복잡한 작업을 계획하고 실행하는 에이전트입니다.
LLM Agent는 도구를 사용하고, 기억을 유지하며, 동적인 행동을 통해 지속적인 작업을 수행할 수 있는 능력을 갖추고 있습니다. 이러한 차이로 인해 LLM Agent는 더 유연하고 강력한 기능을 제공합니다.

## LLM Agent 개발의 파편화와 표준화 필요성

  LLM Agent 구축하는 방식은 프레임워크마다 제각각이었습니다.
- 툴 연동방식이 서로 다름
- 재사용과 확장성 부족
- 시스템간 연동이 어려움

따라서 **표준 프로토콜**의 필요성이 커졌고 해결책으로 MCP 등장

MCP의 기본구조
=====

Host, Client, Server

## Host
LLM Application 자체로 통신의 중심이며 여러 개의 Client 포함하고 이들을 관리

### 특징
- LLM 기반의 인터페이스
- 내부에 MCP Client 포함
- user interface 상호작용
- Client와 연결된 Server들의 실행 결과와 context를 통합해 LLM에 전달

### 역할 요약
- MCP Client들의 초기화 및 라이프사이클 관리
- 인증 및 권한 제어
- 여러 Client로부터 받은 정보를 Context로 통합
- 사용자와 LLM 사이의 브릿지

ex) Claude 사이트, Cursor AI Code Editor

## Client
MCP 서버들과 연결되어있으며, 양방향 메시지 교환 기능 목록 관리, 초기 협상등을 수행

### 특징
- MCP 서버와 연결 (1:1)
- 내부적 메시지 교환 기능, 서버 상태, 기능 목록
- 각 Client는 특정 목적에 맞춰 설계

### 역할 요약
- stateful connection
- 메시지 라우팅 처리

## Server
LLM이 외부 세계와 상호작용 할 수 있도록 도와주는 역할

### 특징
- Tool
  - 외부 API 또는 기능 실행 명령 단위, LLM이 호출 가능
- Resource
  - 텍스트, 로그, DB 스키마 등 외부 Conext 제공
- Prompt Template
  - LLM이 따라야 할 지시문, 형식

### 역할 요약
- LLM이 직접 호출할 수 있는 도구(Tool) 제공
- Host/Client가 요청하는 리소스 정보 제공
- LLM의 행동을 안내할 프롬프트 템플릿 제공
- 초기화 과정에서 프로토콜 협상 수행
- Client로부터 받은 요청을 처리하고 응답 반환


기반 LLM Agent의 동작 흐름
=====

LLM : 일반적인 대화, 단순 질의
LLM Agent : 복잡한 작업 수행, 외부 정보 필요

## LLM 
1. **사용자 입력**: 사용자가 LLM에 질문 또는 요청을 입력합니다.
2. **LLM 처리**: LLM은 메시지 해석하여 Tool 호출 여부 결정하고, 필요한 경우 내부 지식 기반에서 응답을 생성합니다.
3. **응답 반환**: MCP Client를 통해 사용자에게 응답을 반환합니다.

## LLM Agent
1. **사용자 입력**: 사용자가 LLM Agent에 질문 또는 요청을 입력합니다.
2. **LLM Agent 처리**: LLM Agent는 입력을 분석하고, 필요한 경우 Tool 호출 여부를 결정합니다.
3. **Tool 호출**: LLM Agent는 필요한 Tool을 찾은 후, 적절한 파라미터 추출합니다.
4. **Tool 실행**: Client는 요청값을 JSON-RPC 형식으로 변환
5. **Tool 응답 처리**: MCP Server로 요청을 보낸 후, MCP에서는 Tool 관련 기능을 호출하여 처리합니다.
6. **응답 반환**: Tool의 실행 결과(JSON-RPC)를 LLM Agent로 반환하고, LLM Agent는 이를 해석하여 최종 사용자에게 응답을 전달합니다.
